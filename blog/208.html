<!DOCTYPE html>
<html lang="ko">
	<head>
    <title>Apache Kafka :: JDM's Blog</title>
    <!-- # common resource # -->
    <link rel="shortcut icon" href="/images/favicon.ico">
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge">
    <meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0">
    <meta name="author" content="Jung DongMin">
    
    <!-- # css -->
    <link rel="stylesheet" type="text/css" href="//maxcdn.bootstrapcdn.com/font-awesome/4.2.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="//maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="/blog/css/view.min.css">

    <!-- # ad # -->
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
    (adsbygoogle = window.adsbygoogle || []).push({
          google_ad_client: "ca-pub-4675654622926623",
          enable_page_level_ads: true
     });
</script>

    <script src="//cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
    <script src="/blog/scripts/posts.min.js"></script>
    <script src="/blog/scripts/view.min.js"></script>
	</head>
	<body>
    <div id="_gnb" class="text-right">
        <a href="/">Home</a>│<a href="/blog/">Blog</a>│<a href="/guest/">Guestbook</a>│<a href="/lab/">Lab</a>&nbsp;</div>
        <div id="top_subject" class="jumbotron">
            <p id="tob_subject_p1" class="text-center">
                <a href="/blog/">JDM's Blog</a>
            </p>
            <p id="tob_subject_p2"class="text-center">온갖 테스트 결과가 기록되는 이곳은 JDM's Blog입니다. :3</p>
    </div>
		<!-- noscript -->
		<noscript>
      이 사이트의 기능을 모두 활용하기 위해서는 자바스크립트를 활성화 시킬 필요가 있습니다.
      브라우저에서 자바스크립트를 활성화하는 방법(http://www.enable-javascript.com/ko/)을 참고 하세요.
		</noscript>
		<!-- container -->
		<div class="container" id="viewContainer">	
			<!-- content 영역 -->
			<div id="left_wrap" class="col-md-10 col-md-offset-1">
				<!-- 블로그 전문 -->
				<article>
                    <!-- 제목 -->
                    <h1 id="content_title">Apache Kafka</h1>
					<!-- 본문 -->
					<div id="content">
<h2 id="Introduce">Introduce</h2>
<p>아파치 카프카를 공식 홈페이지에서 소개한 내용을 발췌해봤습니다.</p>
<blockquote>
<p>Apache Kafka is publish-subscribe messaging rethought as a distributed commit log.</p>
<p>
<strong>Fast</strong> <br>
A single Kafka broker can handle hundreds of megabytes of reads and writes per second from thousands of clients.<br>
</p>
<p>
<strong>Scalable</strong> <br>
Kafka is designed to allow a single cluster to serve as the central data backbone for a large organization. It can be elastically and transparently expanded without downtime. Data streams are partitioned and spread over a cluster of machines to allow data streams larger than the capability of any single machine and to allow clusters of co-ordinated consumers<br>
</p>
<p>
<strong>Durable</strong> <br>
Messages are persisted on disk and replicated within the cluster to prevent data loss. Each broker can handle terabytes of messages without performance impact.<br>
</p>
<p>
<strong>Distributed by Design</strong> <br>
Kafka has a modern cluster-centric design that offers strong durability and fault-tolerance guarantees.<br>
</p>
<cite><a href="http://kafka.apache.org/">http://kafka.apache.org/</a></cite>
</blockquote>
<p>아파치 카프카는 발행-구독 메시지를 분산 커밋 로그로 다시 생각한 것이고 빠르고, 확장적이고 지속적이면서 분산 환경에 알맞도록 디자인이 되었다고 하네요. 개인적인 느낌은 메시지 큐<span class="refer">Message Queue</span>의 분산 기능을 추가한 것처럼 보입니다.</p>
<p>위에서 확장적<span class="refer">Scalable</span>에서 언급된 것이 눈에 띕니다. 거대한 기관을 위한 중앙 데이터 백본으로써 싱글 클러스터만으로도 서비스 가능하다는 점인데요. 이건 벤치마킹 자료를 검색하면 많이 있어 보일 것 같아서 그냥 지나가는 걸로... :)</p>
<p>그럼 소개는 여기까지만 하고 아파치 카프카를 사용하는 법을 알아봅시다.</p>
<h2 id="Getting_Started_::_Basic">Getting Started :: Basic</h2>
<p>아파치 카프카를 설치하고 구동하는 법을 알아봅시다. 참고한 사이트는 <a href="http://kafka.apache.org/documentation.html#gettingStarted">Apache Kafka :: Getting Started</a>입니다.</p>
<h3 id="Download_Source">Download Source</h3>
<p>처음으로 할 것은 <span class="command">wget</span>으로 카프카를 내려 받는 것입니다. 해당 커맨드가 허용 안된다면 <span class="command">scp</span> 또는 FTP 프로그램 등을 이용해서 파일을 옮깁니다.</p>
<pre class="prettyprint lang-sh">
$ wget http://apache.tt.co.kr/kafka/0.8.2.0/kafka_2.10-0.8.2.0.tgz
$ tar -xzf kafka_2.10-0.8.2.0.tgz
$ ln -s kafka_2.10-0.8.2.0 kafka
$ cd kafka
</pre>
<p>간단한 심볼릭 링크도 걸어뒀습니다.</p>
<h3 id="Start_Zookeeper">Start Zookeeper</h3>
<p>카프카가 구동되기 위해서는 주키퍼가 필요합니다. 아래의 커맨드는 주키퍼 서버 인스턴스를 시작합니다.</p>
<pre class="prettyprint lang-sh">
$ cd bin
$ ./zookeeper-server-start.sh ../config/zookeeper.properties &
</pre>
<h3 id="Start_Kafka">Start Kafka</h3>
<p>주키퍼 서버가 준비되었다면 카프카 브로커<span class="refer">kafka broker</span>를 구동합니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-server-start.sh ../config/server.properties &
</pre>
<h3 id="Create_Topic">Create Topic</h3>
<p>카프카 토픽을 만듭니다. 여기서는 "test" 라는 이름의 토픽을 만들었고 리플리케이션 팩터는 1, 파티션도 1인 토픽입니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
</pre>
<p>리플리케이션 팩터<span class="refer">replication-factor</span>와 파티션<span class="refer">partition</span>은 하단부에서 설명할 예정입니다.</p>
<h3 id="Send__Message">Send  Message</h3>
<p>"test" 토픽에 메시지를 만들어서 보내봅시다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-console-producer.sh --broker-list localhost:9092 --topic test
Test Message.
Hello World!
^C
</pre>
<p>여기서 9092라는 포트를 사용하는 것은 카프카 브로커 구동시 설정한 server.properties에 port=9092 라고 설정 되었기 때문입니다.</p>
<h3 id="Receiving_Message">Receiving Message</h3>
<p>"test" 토픽을 구독하고 메시지를 읽어봅시다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning
Test Message.
Hello World!
^C
</pre>
<h2 id="Getting_Started_::_Single_Host_Multi-broker_Cluster">Getting Started :: Single Host Multi-broker Cluster</h2>
<p>Basic에서 본 내용은 아주 간단한 예제만을 위해 진행했던 코드입니다. 이제부터는 클러스터를 만들어 봅니다. Basic에서부터 예제를 진행했다면 현재는 주키퍼 서버 인스턴스 하나와 카프카 브로커 하나가 돌아가는 상태입니다. 여기서 2개의 카프카 브로커를 추가해봅시다.</p>
<p>즉, 하나의 호스트에 주키퍼와 카프카 브로커가 3개인 구성이 됩니다.</p>
<h3 id="Make_server.properies">Make server.properies</h3>
<p>우선 카프카 브로커 환경 설정을 해야 합니다. {kafka}/config 위치의 server.properties 파일을 각각 다음의 이름으로 복사합니다.</p>
<pre class="prettyprint lang-sh">
$ cp ./server.properties ./server-2.properties
$ cp ./server.properties ./server-3.properties
</pre>
<p>각각의 파일을 다음과 같은 내용으로 수정합니다.</p>
<pre class="prettyprint lang-sh">
# server-2.properties
broker.id=1
port=9093
log.dir=/tmp/kafka-logs-1

# server-3.properties
broker.id=2
port=9094
log.dir=/tmp/kafka-logs-2
</pre>
<h3 id="Start_Kafka">Start Kafka</h3>
<p>{kafka}/bin 에서 아래와 같은 커맨드로 카프카 브로커를 띄웁니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-server-start.sh ../config/server-2.properties &
$ ./kafka-server-start.sh ../config/server-3.properties &
</pre>
<h3 id="Create_Topic">Create Topic</h3>
<p>이번엔 카프카 토픽을 만들때 레플리카<span class="refer">Replica</span>를 만들수 있도록 생성해 봅시다. 여기서 레플리카를 생성할수 있도록 --replication-factor 옵션에 "3"이라는 값을 줍니다. 레플리카를 3곳으로 유지한다는 뜻이죠. 새로 만든 토픽 이름은 "rep_test" 입니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 1 --topic rep_test
</pre>
<div class="green">
<p><strong><i class="fa fa-check fa-lg"></i> TIP. 레플리카(Replica)</strong></p>
<p>레플리카라는 것은 사본이라는 뜻입니다. IT 용어로의 레플리카는 원본 데이터의 손실을 대비해 만들어두는 백업 데이터라 생각하면 됩니다.</p>
</div>
<h3 id="Detail_Topic_Info">Detail Topic Info</h3>
<p>지금 만들어낸 "rep_test" 토픽의 환경설정을 한번 살펴봅시다. 아래와 같은 커맨드를 입력합니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-topics.sh --describe --zookeeper localhost:2181 --topic rep_test
Topic:rep_test  PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: rep_test Partition: 0    Leader: 1   Replicas: 1,0,2 Isr: 1,0,2
</pre>
<p>여기서 리더<span class="refer">Leader</span>는 토픽의 파티션들 중에 어떤 파티션이 읽고 쓰기 위한 권한을 가졌는지 인덱스를 표현합니다. 현재 0번 파티션에 1이 출력되는데 이것은 1번 브로커가 모든 읽기/쓰기에 대한 권한을 가지고 있다는 뜻입니다.</p>
<p>레플리카스<span class="refer">Replicas</span>는 토픽의 사본<span class="refer">Replica</span>이 어떤 브로커에 저장되었는지 목록을 출력합니다. 여기서는 0번 파티션에 레플리카스가 1,0,2가 찍히는데 다시 말하면 0,1,2번 브로커에 사본이 있다는 뜻입니다.</p>
<p>Isr은 레플리카스의 부분집합이기도 하지만 "현재 살아있는 브로커를 표현한다." 보면 편합니다. 즉 현재 동기화 되어 있는 레플리카스의 집합도 됩니다.</p>
<h3 id="Send_Message_to_Cluster">Send Message to Cluster</h3>
<p>이번엔 메시지를 만들어서 보내봅시다. 사실 카프카에서는 "Log"라고 하지만 맥락상 메시지로 임의 표현했습니다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-console-producer.sh --broker-list localhost:9092 --topic rep_test
Hello World! Cluster!
^C
</pre>
<p>0번 카프카 브로커에 "rep_test"라는 토픽으로 메시지를 보낸것입니다.</p>
<h3 id="Receiving_Message_from_Cluster">Receiving Message from Cluster</h3>
<p>이번엔 카프카 클러스터에서 메시지를 받아봅시다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-console-consumer.sh --zookeeper localhost:2181 --from-beginning --topic rep_test
Hello World! Cluster!
^C
</pre>
<h3 id="Fail_Over">Fail Over</h3>
<p>이번엔 클러스터를 이루는 카프카 브로커 하나를 Kill 하고 어떤 변화가 있는지 알아봅시다.</p>
<h4 id="Kill_Kafka_broker">Kill Kafka broker</h4>
<pre class="prettyprint lang-sh">
$ ps -ef | grep server-3.properties
$ kill -9 1234
</pre>
<h4 id="Check_Topic_Info">Check Topic Info</h4>
<p>이번엔 토픽의 정보를 확인해 봅시다.</p>
<pre class="prettyprint lang-sh">
$ ./kafka-topics.sh --describe --zookeeper localhost:2181 --topic rep_test
Topic:rep_test  PartitionCount:1    ReplicationFactor:3 Configs:
    Topic: rep_test Partition: 0    Leader: 1   Replicas: 1,0,2 Isr: 1,0
</pre>
<p>Isr 항목에서 2번 브로커가 빠진 것을 알 수 있습니다.</p>
<h2 id="Multi_Node_Cluster">Multi Node Cluster</h2>
<p>지금까지 하나의 노드에서 카프카 브로커를 하나 또는 세개를 만들어 테스트를 했습니다. 이번엔 멀티 노드 카프카 클러스터를 만들어봅시다. 앞서 말했던 내용과 다른 부분만 언급하겠습니다.</p>
<h3 id="Architecture">Architecture</h3>
<p>지금 만들어볼 카프카 클러스터는 다음과 같은 구성입니다.</p>
<pre class="diagram">
┏━━━━━━━━┓┏━━━━━━━━┓┏━━━━━━━━┓
┃kafka-1.jdm.kr  ┃┃kafka-2.jdm.kr  ┃┃kafka-3.jdm.kr  ┃ * 해당 라인에 있는 것은 Host 이름!
┃┏━━━━━━┓┃┃┏━━━━━━┓┃┃┏━━━━━━┓┃
┃┃Zookeeper   ┃┃┃┃Zookeeper   ┃┃┃┃Zookeeper   ┃┃
┃┗━━━━━━┛┃┃┗━━━━━━┛┃┃┗━━━━━━┛┃
┃┏━━━━━━┓┃┃┏━━━━━━┓┃┃┏━━━━━━┓┃
┃┃Kafka Broker┃┃┃┃Kafka Broker┃┃┃┃Kafka Broker┃┃
┃┗━━━━━━┛┃┃┗━━━━━━┛┃┃┗━━━━━━┛┃
┗━━━━━━━━┛┗━━━━━━━━┛┗━━━━━━━━┛
</pre>
<h3 id="Zookeeper_Configration">Zookeeper Configration</h3>
<p>주키퍼 환경 설정을 해봅시다. 다음과 같은 주키퍼 환경 설정 파일을 각 노드 별로 만들어줍니다.</p>
<pre class="prettyprint lang-sh">
dataDir=/kafka/zookeeper
clientPort=2181
maxClientCnxns=0
initLimit=5
syncLimit=2
server.1=kafka-1.jdm.kr:2888:3888
server.2=kafka-2.jdm.kr:2888:3888
server.3=kafka-3.jdm.kr:2888:3888
</pre>
<p>환경 설정 파일 변경 이후 각 주키퍼 인스턴스에서는 자신의 인스턴스 아이디를 판별하기 위해 myid 라는 파일이 dataDir 속성에 정의된 위치에 존재해야 합니다. 따라서 myid 파일 안에 각 노드에 맞는 아이디를 넣습니다. (ex:1,2,3...)</p>
<p>예를 들어 1번 노드에는 /kafka/zookeeper/myid 라는 파일 내부에 1이라는 값이 있어야 합니다.</p>
<div class="green">
<p><strong><i class="fa fa-check fa-lg"></i> TIP. 주키퍼 스냅샷 파일(Zookeeper snapshot file)</strong></p>
<p>주키퍼는 일정 간격으로 스냅샷을 떠서 파일로 만듭니다. 해당 파일들이 쌓이게 되면 불필요한 디스크 공간을 차지하기 때문에 주기적으로 지워줘야 합니다.</p>
<p>아파치 카프카에 내장된 주키퍼를 사용할때 써볼만한 내용을 공유해봅니다. 자세한 내용은 <a href="http://zookeeper.apache.org/doc/r3.1.2/zookeeperAdmin.html">Maintenance</a> 항목에서 찾을 수 있어요.</p>
<p>아래와 같은 커맨드로 사용 가능합니다. 아래의 커맨드를 수행하면 지정한 개수의 로그만 남기고 삭제를 해줍니다.</p>

<pre class="prettyprint lang-sh">
# ex
$ java -cp zookeeper.jar:log4j.jar:conf org.apache.zookeeper.server.PurgeTxnLog &lt;dataDir&gt; &lt;snapDir&gt; -n &lt;count&gt;
# my
$ cd {kafka}
$ java -cp config:libs/zookeeper-3.4.6.jar:libs/log4j-1.2.16.jar:libs/slf4j-log4j12-1.6.1.jar:libs/slf4j-api-1.7.6.jar org.apache.zookeeper.server.PurgeTxnLog {dataDir} {snapshotDir} {count}
</pre>

<p>주의할 점으로는 <span class="command">count</span> 속성은 <strong>최소 3 이상</strong>이어야 합니다. <span class="refer">*별도로 주키퍼를 설치할땐 bin 디렉토리에 zkCleanup.sh 으로 시작하는 .sh 파일이 있습니다.</span></p>
</div>
<p>이외에도 주키퍼 설정에 대한 자세한 문서는 <a href="https://zookeeper.apache.org/doc/r3.1.2/zookeeperStarted.html">zookeeperStarted</a>를 참조해주세요.</p>
<h3 id="Broker_Configration">Broker Configration</h3>
<p>주키퍼 설정이 끝났고 각 노드별로 주키퍼를 실행해둔 뒤에 아래와 같은 카프카 브로커 설정을 각 노드별로 해줍니다.</p>
<pre class="prettyprint lang-sh">
broker.id=1 # 이부분은 브로커마다 유일한 값을 가져야 합니다.
port=9092
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/kafka/logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
log.retention.check.interval.ms=300000
log.cleaner.enable=false
zookeeper.connect=kafka-1.jdm.kr:2181,kafka-2.jdm.kr:2181,kafka-3.jdm.kr:2181
zookeeper.connection.timeout.ms=6000
</pre>
<p>
<strong>broker.id 값은 반드시 유일한 값을 가져야 합니다.</strong> <br>
그 외의 부분은 동일하게 작성합니다. 다만, 카프카 브로커가 노드별로 더 추가 된다면 log.dirs 속성값을 각 브로커별로 바꿔줄 필요는 있습니다. 예를 들면 /kafka/logs/{broker.id} 처럼 말이죠.<br>
</p>
<p>그외 속성들은 카프카 문서에서 찾아볼 수 있지만 하나를 짚고 가자면 <span class="command">log.retention.hours</span>라는 속성이 있는데 이것이 카프카 메시지(or 로그)를 얼마나 보관해둘지 결정합니다. 단위는 시간(hour)입니다.</p>
<p>브로커 환경 설정까지 끝난 뒤 브로커들을 각 노드별로 실행해주면 멀티 노드 클러스터 구축은 끝난겁니다.</p>
<h2 id="Topic_&_Partition_&_Replication">Topic & Partition & Replication</h2>
<p>소제목에 기술된 용어들의 자세한 내용은 <a href="http://kafka.apache.org/documentation.html">documentation</a>에서 확인 할 수 있습니다. 아래의 내용은 개인적으로 정리해본것입니다.</p>
<p>토픽을 생성하면 기본적으로 파티션 하나는 반드시 가지고 있습니다. 하지만 클러스터에서는 하나일 필요는 없기 때문에 파티션의 개수가 많아지는 경향이 있습니다.</p>
<p>파티션이 여러개 있는 토픽인 경우, 메시지를 전달할 때 파티셔닝 알고리즘(기본은 랜덤)에 의해 하나의 파티션을 정해 보내게 됩니다. 또한 파티션들은 하나의 노드가 아니라 클러스터를 이루는 모든 노드에 분산됩니다.</p>
<p>따라서 하나의 토픽이 클러스터를 이루는 노드들에 고르게 분산될 정도의 충분한 파티션 개수를 가진다면 하나의 노드가 받는 부하가 줄어들 수 있습니다.</p>
<p>그리고 고가용성을 위해 파티션을 복제하게 되는데 이것을 리플리케이션 팩터 값을 통해 정의할 수 있습니다. 파티션 자체를 복제하고 나중에 문제가 생기면 파티션 단위로 Fail Over를 하게 됩니다. 심지어 노드가 다운되더라도 Fail Over가 되는데 이것은 복제한 파티션들이 다른 노드에도 존재하기 때문에 가능합니다. (물론 이 경우는 모든 노드에 파티션이 할당 될 정도의 충분한 파티션 개수를 가진 토픽에 한정합니다.)</p>
<h2 id="Monitoring_tool">Monitoring tool</h2>
<p>깃헙에 <a href="https://github.com/yahoo/kafka-manager">https://github.com/yahoo/kafka-manager</a>라는 도구가 있네요. 설치는 추후에 시간이 나면... :)</p>
<p><a href="https://github.com/linkedin/Burrow">https://github.com/linkedin/Burrow</a> 이것도 한번 보세요!</p>
<h2 id="System_Tools">System Tools</h2>
<p>모니터링 툴 대신 <a href="https://cwiki.apache.org/confluence/display/KAFKA/System+Tools">https://cwiki.apache.org/confluence/display/KAFKA/System+Tools</a>을 사용해 볼 수도 있어요.</p>
<h2 id="Closing_Remarks">Closing Remarks</h2>
<p>너무 정신없이 정리했습니다. 잘못된 부분 있으면 댓글 부탁드립니다. ^^ 추가적인 내용도 좋습니다!</p>
<h2 id="추가사항(2016.06.01)">추가사항(2016.06.01)</h2>
<p>카프카 브로커 구동시에 다음과 같은 옵션을 주면 모니터링 도구에서 JMX을 이용한 값을 조회할 수 있습니다. 또한 데몬으로 구동시에 옵션을 주면 좋습니다.</p>
<pre class="prettyprint lang-sh">
$ JMX_PORT=9997 ./kafka-server-start.sh -daemon ./server.properties
</pre>
</div>
				</article>
			</div>
			<!-- // content 영역 -->
		</div>
		<!-- # code highlight -->
		<script src="//cdn.jsdelivr.net/gh/google/code-prettify@master/loader/run_prettify.js?lang=scala&lang=sql&lang=kotlin&lang=yaml&skin=sons-of-obsidian"></script>
		<script src="/lib/scripts/footer.js"></script>
	</body>
</html>
