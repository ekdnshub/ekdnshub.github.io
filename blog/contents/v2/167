###info
title=Apache Spark Cluster(Standalone)
created=2015-07-06
ad=true
category=Spark
tags=Spark
###
#p 이번 포스팅은 Spark(이하 "스파크")에서 "Standalone" 배포하는 법에 알아고보자 합니다. 여기서는 호스트 한대로만 진행 할 예정입니다. 호스트(혹은 노드)가 두대 이상인 경우 ssh 구성을 해야 하지만 여기서는 제가 가진 자원의 한계로(...) 한대로만 진행합니다. 이 포스팅은 {$https://spark.apache.org/docs/latest/spark-standalone.html|spark-standalone}의 정보에 기반합니다.

#h2 Install Spark
#p 스파크를 설치하는 방법은 {$/blog/164|Apache Spark Overview & Example} 항목을 참조하시기 바랍니다.


#h2 Setup & Start Spark Cluster
#p 스파크 Standalone 클러스터 구축은 간단합니다. 우선 Master 인스턴스를 띄우고 그 뒤에 Worker 인스턴스를 붙여주면 됩니다.


#h3 Start Master
#p Master 인스턴스를 띄우기 위해서는 `SPARK_HOME/sbin/start-master.sh`을 실행해야 합니다.

###console
$ ./start-master.sh
###
#p 위와 같은 쉘 커맨드를 입력하게 되면 스파크 Master 인스턴스가 올라갑니다. 기본적으로 7077번 포트를 사용합니다.

#h4 Access Spark Web UI
#p Master 인스턴스 기동 후 `http://localhost:8080`으로 접속하게 되면 Master 및 클러스터에 대한 구성 정보가 일목요연하게 나옵니다. 아직 Workers 항목은 기동된 Worker 인스턴스가 없기 때문에 아무것도 없습니다. 만약 8080 포트가 다른 프로세스(ex. 톰캣)등에 선점 되어 있다면 8081 포트로 접속이 가능합니다.

#h3 Setup Worker Configuration
#p Master 인스턴스 기동 후 이번엔 Worker 인스턴스 환경 설정을 해줘야 합니다.


###console
$ cd SPARK_HOME/conf
$ cp spark-env.sh.template spark-env.sh
###

#p 복사된 `spark-env.sh` 파일에 다음과 같은 정보를 입력합니다.

###code.sh
# spark-env.sh
export SPARK_WORKER_INSTANCES=3
###

#p 이 값은 Worker로 돌릴 인스턴스의 개수를 지정합니다. 적당히 지정하면 됩니다.


#h3 Start Worker
#p 환경 설정이 끝났다면 `SPARK_HOME/sbin/start-slave.sh`을 실행해야 합니다.


###console
$ ./start-slave.sh spark://your_host_name:7077
# ./start-slave.sh spark://your_host_name:7077 -m 512M -c 1
# -m 은 워커가 사용할 메모리 지정
# -c 은 워커가 사용할 코어 개수 지정
###

#p 위에서 `spark://`값은 Master Web UI에 최상단에 {!URL}이라는 항목에 있는 값입니다.

#p 여기까지 진행이 잘 됐다면 Web UI의 {!Workers} 항목에 3개의 워커가 등록됩니다.

#h2 Test Spark Cluster
#p 간단하게 클러스터 구축이 끝났습니다. 이제는 써봐야겠지요. Master 인스턴스에 접속하기 위해 `SPARK_HOME/bin/spark-shell`을 이용합시다.


#h3 Test Console
#p 다음과 같은 커맨드로 스파크 클러스터에 접속합니다.

###console
$ ./spark-shell --master spark://your_host_name:7077
###
#p {$https://spark.apache.org/docs/latest/quick-start.html|간단한 예제} 하나 돌려보면서 Master의 Web UI에서 어떤 것이 추가 되는지 지켜보세요. :D

###fold.Example
###console
scala> <span class="light">val textFile = sc.textFile("README.md")}
...
scala> <span class="light">textFile.count()}
###
###

#h4 Log4j Properties
#p 스파크 콘솔을 시작할 때 log4j 프로퍼티를 지정하라고 뜨는데 아래와 같은 커맨드로 log4j 프로퍼티 파일을 복사 하신 뒤 세부 설정을 하시면 됩니다.

###console
$ cd SPARK_HOME/conf
$ cp log4j.properties.template log4j.properties
###

#p 아래는 console 대신 file에 출력하도록 일부 설정을 변경한 log4j.properties 파일입니다.

###console
# Set everything to be logged to the console
log4j.rootCategory=INFO, console
log4j.appender.console=org.apache.log4j.<span class="light">FileAppender}
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n
log4j.appender.console.file=SPARK_HOME/your_log_file.log

# Settings to quiet third party logs that are too verbose
log4j.logger.org.spark-project.jetty=WARN
log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
###

#h3 Worker Monitoring
#p 각 Worker의 작업 내역은 Master의 Web UI에서 확인하거나 또는 `SPARK_HOME/work/`에서 확인 가능합니다.


#h2 Closing Remarks
#p 스파크 클러스터 "Standalone" 모드로 실행 및 테스트를 해봤습니다. :D
